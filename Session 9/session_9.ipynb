{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b03bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Data Science\n",
    "## Session 9\n",
    "### Other data type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daffe2f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e443fb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "\n",
    "1. Image manipulation (PIL, OpenCV)  \n",
    "\n",
    "2. Basic use of algorithms (Scikit-image, Kornia)  \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85462b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Other data type\n",
    "### Image manipulation\n",
    "\n",
    "One of the most important fields within **Artificial Intelligence** is **Computer Vision**. Until very recently, most impactful publications were made in this field. \n",
    "Although the foundations of **Deep Learning** were made many decades ago (80s-90s), the big achievements made in Computer Vision back in 2012 catalyzed a wave of research and industry adoption of deep learning. \n",
    "\n",
    "In this new wave many fields ignificantly benefited from it, Audio and Speech Recognition, Natural Language Processing, Healthcare and Medicine, Robotics, Cybersecurity, Earth Observation, Agriculture and many others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9711d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Image manipulation\n",
    "\n",
    "An image is usually represented as a 2D (grayscale) or 3D (RGB) matrix. Each of the RGB dimensions, red, green and blue are known as bands or channels. In some fields, like Earth Observation, we can work with images with multiple bands (up to thousands in some cases, known as hyperspectral images).\n",
    "\n",
    "<img align=\"center\" width=\"200px\" src=\"session_9_files/rgb.png\">\n",
    "\n",
    "Note: Depending on the library rows and columns may be switched. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b25dc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Image manipulation\n",
    "\n",
    "In this session, we will work with images. Many applications make use of cameras in surveillance, medicine, advanced driving assistance, Earth observation, etc.\n",
    "\n",
    "As in many other fields, Python offers very powerful libraries to manipulate and visualize images. Among them, **Pillow** and **OpenCV** ar two of the most popular ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be8d7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Image manipulation\n",
    "\n",
    "Images most of the times come in **uint8** or **uint16**, although there are some exceptions. In the first case, the range values are integers from 0 to 255, in the second case, from 0 to 65535. So depending on the application, we may see them in one or the other, although uint8, aka **byte**, is the most current one.\n",
    "\n",
    "Let's start with Pillow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3cc3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# to install it in your environment: python -m pip install Pillow\n",
    "\n",
    "print(2**16)\n",
    "\n",
    "# to make use of Pillow, we will use its Image module\n",
    "from PIL import Image \n",
    "\n",
    "# Notebook will directly open the image without the need of using Matplotlib\n",
    "img = Image.open('session_9_files/python_logo.jpeg') \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5a132",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The Image object offers the following methods to get some info:\n",
    "    - format\n",
    "    - size\n",
    "    - mode\n",
    "'''\n",
    "\n",
    "print(f\"format: {img.format}\\nsize: {img.size} \\nmode: {img.mode}\")\n",
    "\n",
    "# Note: It's important to mention that Pillow does not decode or load the raster \n",
    "# data unless it really has to. Hence, methods like format, size or mode won't load\n",
    "# the whole image into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317894c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Additionally, Pillow offers through the Image class other methods\n",
    "'''\n",
    "\n",
    "# THUMBNAIL\n",
    "size = (32, 32)\n",
    "img.thumbnail(size)\n",
    "\n",
    "# SAVE\n",
    "outfile = 'python_logo_small.thumbnail'\n",
    " # Since thumbnail is not an standard extension, we specify the format\n",
    "img.save(outfile, format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903f879",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Crop method -> (0, 0, 4, 4)\n",
    "    \n",
    "Original:\n",
    "\n",
    "|  1  2  3  4  5  6 |\n",
    "|  7  8  9 10 11 12 |\n",
    "| 13 14 15 16 17 18 |\n",
    "| 19 20 21 22 23 24 |\n",
    "| 25 26 27 28 29 30 |\n",
    "| 31 32 33 34 35 36 |\n",
    "\n",
    "Cropped:\n",
    "\n",
    "|  1  2  3  4 |\n",
    "|  7  8  9 10 |\n",
    "| 13 14 15 16 |\n",
    "| 19 20 21 22 | \n",
    "'''\n",
    "\n",
    "# CROP\n",
    "img = Image.open('session_9_files/python_logo.jpeg')\n",
    "\n",
    "box = (0, 0, 128, 128) # Images (0,0) coordinates are the top left \n",
    "cropped = img.crop(box)\n",
    "cropped # this is again an Image class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e0c4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Transpose method comes with different options:\n",
    "\n",
    "Image.Transpose.ROTATE_90\n",
    "Image.Transpose.ROTATE_180\n",
    "Image.Transpose.ROTATE_270\n",
    "Image.Transpose.FLIP_LEFT_RIGHT\n",
    "Image.Transpose.FLIP_TOP_BOTTOM\n",
    "...\n",
    "\n",
    "'''\n",
    "\n",
    "# TRANSPOSE\n",
    "transpose = cropped.transpose(Image.Transpose.ROTATE_180) # 90, 180, 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2cea3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Paste and copy methods\n",
    "\n",
    "by providing a box, same as we do with crop, we can paste anything \n",
    "we want into the image object\n",
    "\n",
    "'''\n",
    "\n",
    "# COPY\n",
    "# it will simply create a copy, in case we want to keep the original,\n",
    "# since the method paste is performed inplace\n",
    "img_copy = img.copy() \n",
    "img\n",
    "\n",
    "# PASTE\n",
    "img.paste(transpose, box) \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cf025",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Paste and new methods\n",
    "\n",
    "We will create an empty RGB image and paste two images into it\n",
    "\n",
    "'''\n",
    "# let's create a new image that will contain both next to each other\n",
    "img_1 = Image.open('session_9_files/python_logo.jpeg')\n",
    "img_2 = Image.open('session_9_files/python_logo.jpeg')\n",
    "\n",
    "w = img_1.size[0] + img_2.size[0] # width together\n",
    "h = max(img_1.size[1], img_2.size[1]) # maximum height\n",
    "\n",
    "#Â what happens if we go beyond the size?\n",
    "# w *= 2/3\n",
    "# w = int(w)\n",
    "\n",
    "img = Image.new(\"RGB\", (w, h))\n",
    "\n",
    "img.paste(img_1)\n",
    "img.paste(img_2, (img_1.size[0], 0))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f57b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split and merge methods\n",
    "\n",
    "These two methods will permit us to separate and stack bands\n",
    "'''\n",
    "img = Image.open('session_9_files/python_logo.jpeg')\n",
    "r, g, b = img.split()\n",
    "img = Image.merge(\"RGB\", (b, g, r)) # we switch red with blue\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d7d48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Resize and rotate\n",
    "\n",
    "These two methods will permit us to separate and stack bands\n",
    "\n",
    "We will also use imshow from Matplotlib\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_1 = img.resize((128, 128))\n",
    "# degrees counter-clockwise\n",
    "out_2 = img.rotate(45) # missing values are set to 0s\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(out_1)\n",
    "#plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(out_2)\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393f027",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Other methods can be pretty useful such as:\n",
    "    - contain\n",
    "    - cover\n",
    "    - fit\n",
    "    - pad\n",
    "'''\n",
    "\n",
    "from PIL import ImageOps\n",
    "\n",
    "print(f\"Original size: {img.size}\")\n",
    "\n",
    "size = (100, 75)\n",
    "\n",
    "img_1 = ImageOps.contain(img, size)\n",
    "img_2 = ImageOps.cover(img, size)\n",
    "img_3 = ImageOps.fit(img, size)\n",
    "img_4 = ImageOps.pad(img, size, color=\"#f00\")\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(141)\n",
    "plt.title(img_1.size)\n",
    "#plt.axis([0, img.size[0], 0, img.size[1]])\n",
    "plt.imshow(img_1)\n",
    "plt.subplot(142)\n",
    "plt.title(img_2.size)\n",
    "plt.imshow(img_2)\n",
    "plt.subplot(143)\n",
    "plt.title(img_3.size)\n",
    "plt.imshow(img_3)\n",
    "plt.subplot(144)\n",
    "plt.title(img_4.size)\n",
    "plt.imshow(img_4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122996d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Convert method: color conversion \n",
    "'''\n",
    "img = Image.open('session_9_files/python_logo.jpeg')\n",
    "converted = img.convert(\"L\") # to gray scale, not an inplace method\n",
    "#print(converted.mode)\n",
    "# It converts colors into 216 colors optimized for web display\n",
    "#converted = img.convert(\"P\",palette=Image.Palette.WEB) \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(converted, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986241c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "filter method and ImageEnhance module: to enhance the images\n",
    "\n",
    "'''\n",
    "\n",
    "from PIL import ImageEnhance\n",
    "from PIL import ImageFilter\n",
    "\n",
    "# it sharpens the edges and removes some noise\n",
    "filtered = img.filter(ImageFilter.DETAIL)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(filtered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347f65a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "enh = ImageEnhance.Contrast(img)\n",
    "enhanced = enh.enhance(1.3)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(enhanced) # here \n",
    "plt.show()\n",
    "\n",
    "# we can also call show() from Pillow, but note that it will open a new window\n",
    "# outside your notebook\n",
    "# enh.enhance(1.3).show(\"30% more contrast\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe76fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Point method: modify the image at the pixel level\n",
    "'''\n",
    "\n",
    "from PIL import ImageFilter\n",
    "\n",
    "# we multiply by 2 each pixel \n",
    "modified = img.point(lambda x: x * 2) # or / 2 to make it darker\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(modified) # we saturate the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70722b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Image manipulation\n",
    "\n",
    "One of the most extended libraries that have been used in many real-time applications is **OpenCV**. This library not just offers support for **Python** but also for **C++**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2834c9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Let's start with opening an image\n",
    "'''\n",
    "\n",
    "#Â to install it: !python -m pip install opencv-python\n",
    "\n",
    "import cv2 as cv # typical import, although some people use cv2\n",
    "\n",
    "cv.imread('session_9_files/esade.jpeg') # it returns a numpy array, and we know how to work with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97256aab",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Since we know how to work with numpy, any single operation we\n",
    "know should work in these 2D and 3D matrices\n",
    "'''\n",
    "\n",
    "img = cv.imread('session_9_files/python_logo.jpeg') # it returns a numpy array, and we know how to work with them!\n",
    "\n",
    "plt.imshow(img) # What's going on with the color? \n",
    "plt.show()\n",
    "\n",
    "# Note: OpenCV returns BRG, instead of RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720eac4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cvcolor method: to change color space\n",
    "'''\n",
    "\n",
    "#Â changing to HSV color space\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "# we can do the same to get back to RGB\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(rgb)\n",
    "plt.title('RGB')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.title('HSV')\n",
    "plt.axis('off')\n",
    "plt.imshow(hsv) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114abb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Resize method: scale your image\n",
    "\n",
    "'''\n",
    "\n",
    "scaled_by_size = cv.resize(img, (150, 300), interpolation = cv.INTER_CUBIC)\n",
    "scaled_by_factor = cv.resize(img, None, fx=2, fy=2, interpolation = cv.INTER_NEAREST)\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.subplot(132)\n",
    "plt.title('Scaled by size')\n",
    "plt.imshow(scaled_by_size) \n",
    "plt.subplot(133)\n",
    "plt.title('Scaled by factor')\n",
    "plt.imshow(scaled_by_factor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd861f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "warpAffine method: to perform translations, rotations and reflections.\n",
    "\n",
    "As a proper geometry transformation, we need to define the transformation matrix\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('session_9_files/esade.jpeg')\n",
    "img = img[:,:,[2,1,0]] # From BGR to RGB\n",
    "rows, cols, _ = img.shape # shape method from numpy\n",
    " \n",
    "'''\n",
    "Transformation T and point P:\n",
    "\n",
    "T = | 1  0  4 |\n",
    "    | 0  1  5 |\n",
    "    | 0  0  1 |\n",
    "\n",
    "P = | 2 |\n",
    "    | 3 |\n",
    "    | 1 |\n",
    "    \n",
    "New point:\n",
    "    \n",
    "P' = T * P =\n",
    "    | 1  0  4 |   | 2 |   | 2 + 4 |   | 6 |\n",
    "    | 0  1  5 | * | 3 | = | 3 + 5 | = | 8 |\n",
    "    | 0  0  1 |   | 1 |   |   1   |   | 1 |\n",
    "\n",
    "'''\n",
    "    \n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "# rotating 45 degrees \n",
    "#M = np.float32([[np.cos(np.pi/4), -np.sin(np.pi/4), 0],[np.sin(np.pi/4), np.cos(np.pi/4),0]])\n",
    "print(M)\n",
    "translated = cv.warpAffine(img, M, (cols,rows))\n",
    " \n",
    "    \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.title('Translated')\n",
    "plt.axis('off')\n",
    "plt.imshow(translated) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21956668",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "getAffineTransform method: To get the affine transformation between points into \n",
    "different places and transform the image, pretty useful in multiple applications\n",
    "\n",
    "'''\n",
    "\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    " \n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    " \n",
    "transformed = cv.warpAffine(img, M, (cols,rows))\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.plot([50, 200, 50], [50, 50, 200], '*r', markersize=10)\n",
    "plt.subplot(122)\n",
    "plt.imshow(transformed)\n",
    "plt.plot([10, 200, 100], [100, 50, 250], '*g', markersize=10)\n",
    "plt.title('Transformed')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a490a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "threshold method: We can also apply thresholds to images\n",
    "\n",
    "cv.THRESH_{different types}: THRESH_BINARY_INV, THRESH_TRUNC,\n",
    "THRESH_TOZERO, THRESH_TOZERO_INV\n",
    "\n",
    "These methods are in some cases used for pre-processing images\n",
    "\n",
    "'''\n",
    "\n",
    "img = cv.imread('session_9_files/esade.jpeg', cv.IMREAD_GRAYSCALE) # we load the grayscale version\n",
    "\n",
    "_, thresh = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "manual = np.where(img >= 127, 255, 0)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(132)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholded')\n",
    "plt.subplot(133)\n",
    "plt.imshow(manual, cmap='gray')\n",
    "plt.title('Manual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc00076",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "There are other threshold methods such as Adaptive Thresholding or OTSU's.\n",
    "\n",
    "'''\n",
    "\n",
    "img = cv.imread('session_9_files/esade.jpeg', cv.IMREAD_GRAYSCALE)\n",
    " \n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "\n",
    "adapt2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "adapt3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(221)\n",
    "plt.title('Original')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.yticks([]), plt.xticks([])\n",
    "plt.subplot(222)\n",
    "plt.title('Binary th')\n",
    "plt.imshow(th1, cmap='gray')\n",
    "plt.yticks([]), plt.xticks([])\n",
    "plt.subplot(223)\n",
    "plt.title('Adaptative Mean')\n",
    "plt.imshow(adapt2, cmap='gray')\n",
    "plt.yticks([]), plt.xticks([])\n",
    "plt.subplot(224)\n",
    "plt.title('Adaptative Gaussian')\n",
    "plt.imshow(adapt3, cmap='gray')\n",
    "plt.yticks([]), plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a3c9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Otsu finds out of the binomial distribution the best threshold to split the values\n",
    "'''\n",
    "\n",
    "th, otsu = cv.threshold(img, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "plt.title('Otsu')\n",
    "plt.imshow(otsu, cmap='gray')\n",
    "plt.yticks([]), plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d6786",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "filter2D, Blur, GaussianBlur, bilateralFilter methods: to filter images\n",
    "\n",
    "'''\n",
    "\n",
    "img = cv.imread('session_9_files/lena.jpg')[...,[2,1,0]]\n",
    "\n",
    "# we create the filter\n",
    "kernel = np.ones((5,5),np.float32)/25 # A 5x5 filter \n",
    "# this filter averages all pixel values\n",
    "\n",
    "# filter image\n",
    "filtered = cv.filter2D(img,-1,kernel)\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(filtered)\n",
    "plt.title('Filtered')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# History of Lena: https://the.me/the-story-of-lena/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc89e30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Blur images, it's the same as averaging\n",
    "blurred = cv.blur(img,(5,5)) # try a bigger filter\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(blurred)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e6344",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Gaussian blur images\n",
    "blurred = cv.GaussianBlur(img,(5,5),0) # try a bigger filter\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(blurred)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1444bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Median blur images\n",
    "blurred = cv.medianBlur(img, 5) # try a bigger filter\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(blurred)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da791c",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Bilateral filter blur images\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import seaborn as sns\n",
    "\n",
    "# adding noise\n",
    "np.random.seed(1234)\n",
    "\n",
    "std = 20\n",
    "mean = 0 \n",
    "gaussian_noise = np.random.randn(*img.shape) * std + mean\n",
    "\n",
    "noisy = img.copy() + gaussian_noise\n",
    "noisy = np.clip(noisy, 0, 255).astype('uint8')\n",
    "\n",
    "# sns.histplot(noise.flatten()) # to visualize the random values \n",
    "# plt.show()\n",
    "\n",
    "blurred = cv.bilateralFilter(img,9,75,75) # try a bigger filter\n",
    " \n",
    "plt.subplot(121)\n",
    "plt.imshow(noisy)\n",
    "plt.title('Noisy')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(blurred)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d61d52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dilate and erode methods: to transform the image morphologically\n",
    "\n",
    "These methods are usually applied on binary images.\n",
    "\n",
    "'''\n",
    "img = cv.imread('session_9_files/j.png')\n",
    "\n",
    "# same way we created a filter before, we use one now\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv.erode(img, kernel, iterations = 1)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(erosion), plt.title('Eroded'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca0467",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the same using dilated\n",
    "dilated = cv.dilate(img, kernel, iterations = 1)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(dilated), plt.title('Dilated'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bcedd8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "morphologyEx method: to apply other type of transformations\n",
    "\n",
    "Another interesting one is gradient, that allow us to extract edges.\n",
    "'''\n",
    "kernel = np.ones((3,3))\n",
    "gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(gradient), plt.title('Gradient'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb016f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Laplacian, Sobel and Canny edge detector methods \n",
    "'''\n",
    "img = cv.imread('session_9_files/esade.jpeg', cv.IMREAD_GRAYSCALE)\n",
    "laplacian = cv.Laplacian(img,cv.CV_64F)\n",
    "sobelx = cv.Sobel(img,cv.CV_64F,1,0,ksize=5) # in different direction, x\n",
    "sobely = cv.Sobel(img,cv.CV_64F,0,1,ksize=5) # in different direction, y\n",
    "edges = cv.Canny(img,100,200)\n",
    "\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Canny'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47d928",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Another useful tool is the countours method: to find objects in binary images\n",
    "\n",
    "'''\n",
    "\n",
    "# read Esade logo image\n",
    "img = cv.imread('session_9_files/esade_logo.jpg')\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "grad = cv.Canny(gray,100,200)\n",
    "\n",
    "# plt.imshow(grad, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "contours, hierarchy = cv.findContours(grad, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    " \n",
    "print(\"Number of Contours found = \" + str(len(contours))) \n",
    "\n",
    "    \n",
    "# area \n",
    "area = cv.contourArea(contours[2])\n",
    "print(f\"Contour area of index 2 is: {area}\")\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(121), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "\n",
    "cv.drawContours(img, [contours[2]], -1, (255, 0, 255), 3)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(img), plt.title('Gradient'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcd518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Image manipulation\n",
    "\n",
    "Exercise: \n",
    "- Can you count the coins you have in *coins.jpg*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eeecb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "## Basic use of algorithms \n",
    "\n",
    "Let's see what other big libraries like **scikit-image** and **kornia** can offer. In the case of scikit-image, we will look at some of the methods and their simplicity compared to OpenCV. Similar to opencv, our images are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b9511",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# to install scikit-image: !python -m pip install scikit-image\n",
    "'''\n",
    "color, io and util modules: to manipulate an image\n",
    "'''\n",
    "import skimage as ski\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = ski.io.imread('session_9_files/lena.jpg') # read image\n",
    "hsv = ski.color.rgb2hsv(img) # HSV\n",
    "gray = ski.color.rgb2gray(img) # GRAY\n",
    "inverted_img = ski.util.invert(img) # INVERT, negative effect\n",
    "\n",
    "plt.subplot(141), plt.imshow(img), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(142)\n",
    "plt.imshow(hsv), plt.title('HSV'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(143)\n",
    "plt.imshow(gray, cmap='gray'), plt.title('Gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(144)\n",
    "plt.imshow(inverted_img), plt.title('Inverted'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b63377",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Segmenting an image using Superpixels\n",
    "'''\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "coins = ski.io.imread('session_9_files/coins.jpg') # we can also read images\n",
    "coins = ski.color.rgb2gray(coins)\n",
    "\n",
    "# Make segmentation using SLIC superpixels.\n",
    "seg = slic(\n",
    "    coins,\n",
    "    n_segments=500,\n",
    "    max_num_iter=500,\n",
    "    sigma=1,\n",
    "    compactness=0.75,\n",
    "    channel_axis=None,\n",
    "    start_label=0,\n",
    ")\n",
    "\n",
    "colored = label2rgb(seg, image=coins, image_alpha=0.5,)\n",
    "\n",
    "plt.subplot(121), plt.imshow(coins), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(colored), plt.title('Superpixels'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fc37f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Let's play with the exposure module to perform stretching and equalization\n",
    "'''\n",
    "\n",
    "# Load the moon image from Scikit-Image\n",
    "img = ski.data.moon()\n",
    "\n",
    "# Contrast stretching\n",
    "p2, p98 = np.percentile(img, (2, 98)) # we optain the percentile values at 2 and 98\n",
    "img_rescale = ski.exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "# Equalization: making a picture clearer by spreading out the colors evenly\n",
    "# this way, bright and dark areas are easier to visualize\n",
    "img_eq = ski.exposure.equalize_hist(img)\n",
    "\n",
    "# Adaptive Equalization\n",
    "img_adapteq = ski.exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(141), plt.imshow(img, cmap='gray'), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_rescale, cmap='gray'), plt.title('Streched'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_eq, cmap='gray'), plt.title('Equalized'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(144)\n",
    "plt.imshow(img_adapteq, cmap='gray'), plt.title('Equalized Adaptive'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4baf69",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Another method within the morphology module is skeletonize\n",
    "'''\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import invert\n",
    "\n",
    "img = ski.io.imread('session_9_files/elephant.jpg')\n",
    "img = ski.color.rgb2gray(img)\n",
    "\n",
    "# invert the image\n",
    "image = invert(img) # float values [0, 1]\n",
    "image = image > 0.1\n",
    "image = cv.dilate(image.astype('uint8'), (15,15), iterations=15)\n",
    "\n",
    "# perform skeletonization\n",
    "skeleton = skeletonize(image)\n",
    "\n",
    "plt.subplot(121), plt.imshow(image), plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122)\n",
    "plt.imshow(skeleton), plt.title('Superpixels'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9a8c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Template Matching can be performed with OpenCV and Scikit-learn.\n",
    "Here, we will use scikit-learn for its simplicity\n",
    "Scikit-image example!\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.feature import match_template\n",
    "\n",
    "\n",
    "image = data.coins()\n",
    "coin = image[170:220, 75:130]\n",
    "\n",
    "result = match_template(image, coin)\n",
    "# over the matching result we get the one with highest response\n",
    "ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "x, y = ij[::-1]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 3, 1), plt.imshow(coin, cmap='gray'), plt.title('Template')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2), plt.imshow(image, cmap='gray'),  plt.title('Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "hcoin, wcoin = coin.shape\n",
    "plt.Rectangle((x, y), wcoin, hcoin, edgecolor='r', facecolor='none')\n",
    "plt.title('`match_template`\\nresult')\n",
    "plt.imshow(result)\n",
    "plt.plot(x, y, 'o', markeredgecolor='r', markerfacecolor='none', markersize=10)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc79f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Histogram matching method can be useful when transforming an image\n",
    "into the same color histogram\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage import exposure\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "reference = ski.io.imread('session_9_files/avatar.jpg')\n",
    "image = data.chelsea()\n",
    "\n",
    "matched = match_histograms(image, reference, channel_axis=-1)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image)\n",
    "plt.title('Source')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(reference)\n",
    "plt.title('Reference')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(matched)\n",
    "plt.title('Matched')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb4763",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Basic use of algorithms \n",
    "\n",
    "One of the most trending open-source libraries in recent years is **Kornia**. Developed by Catalan researcher Edgar Riba, this library offers a wide range of features, making it a standout tool for modern computer vision applications. Among it features, we can find:\n",
    "\n",
    "1. Geometric transformations\n",
    "2. Image filtering\n",
    "3. Feature detection and matching\n",
    "4. Optical flow\n",
    "5. Camera models and calibration\n",
    "\n",
    "While there are other libraries offering similar features, Kornia distinguishes itself by being built on top of PyTorch. Like PyTorch, it is a user-friendly library that leverages GPUs for high efficiency. Moreover, thanks to the contributors behind the scenes, latest implementations are usually available in Kornia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39947438",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Basic use of algorithms\n",
    "\n",
    "We will use a face detector already available in Kornia, to detect faces and blur them.\n",
    "\n",
    "Let's use Colab: https://kornia.github.io/tutorials/nbs/face_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13aaf87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data type\n",
    "### Exercise\n",
    "\n",
    "For this session, we won't have any assignment! If there's any time left, let's use it to finish previous assignments, or work in the group project."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
